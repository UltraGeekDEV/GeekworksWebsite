{"HighlightImageNames":["Images/Devlog1/Banner.png"],"Projects":[{"Devlogs":[{"Paragraphs":[{"Id":0,"Type":"h4","ImageSide":0,"ImageName":"","Text":"Is There More to Discover?"},{"Id":1,"Type":"p","ImageSide":0,"ImageName":null,"Text":"It's easy to think that slicers are starting to reach their limits. We are seemingly approaching a point where the limiting factor is our hardware. This may be true when it comes to speed but not quality. We still have to deal with the rough underside of overhangs and stair-stepping. But are we sure that this is how far can we push our printers? Have we ventured far enough from the norm of planar slicing to see whether we are actually at the summit? Have we dared to backtrack far enough to realize we took the wrong turn? I think not!"},{"Id":2,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"Novel Slicing Strategies"},{"Id":3,"Type":"p","ImageSide":3,"ImageName":"ConicalVsPlanar.png","Text":""},{"Id":4,"Type":"p","ImageSide":1,"ImageName":"singleConeConical.webp","Text":"Our first stop in our journey takes us to <a href=\"https://www.mdpi.com/2076-3417/11/18/8760\" target=\"_blank\" rel=\"noopener noreferrer\">conical slicing</a>. A method that is very similar to traditional slicing techniques. The only difference is that it uses a cone instead of a plane. Which enables the printing of horizontal overhangs. Although it can help with overhangs it doesn't eliminate the underlying issue. It instead shifts our overhang capabilities in one direction. As such masking the problem without truly addressing it."},{"Id":5,"Type":"p","ImageSide":2,"ImageName":"multiConeConical.webp","Text":"To address this directionality we could fit cones to every overhang. This however complicates the slicing algorithms used. Or the user could assign them manually but this would heavily reduce usability. The next major issue this method has is printer compatibility. It was meant for use with 4-axis printers, where the hotend can rotate around the cone's center. This allows for improved clearance compared to 3-axis printers."},{"Id":6,"Type":"p","ImageSide":0,"ImageName":null,"Text":"Reducing the cone's slope can improve the required clearance. This inevitably compromises overhang capability, as the two are directly linked. As a result, this method may excel on more complex printers. But my goal is good compatibility with current I3-style printers. To attain supportless slicing we will need to venture further from the norm."},{"Id":7,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"Wait So You DON'T Need Overlap?"},{"Id":8,"Type":"p","ImageSide":0,"ImageName":null,"Text":"The previously mentioned methods used the overlap with the previous layer to act as support to the overhang... but is the issue the lack of overlap or the geometry of the layer? Turns out it may be the latter. This method ventured far from the norm. It attaches plastic to the side of already printed areas. With <a href=\"https://github.com/stmcculloch/arc-overhang\" target=\"_blank\" rel=\"noopener noreferrer\">arc overhangs</a>, we can print horizontal overhangs in any direction on any printer."},{"Id":9,"Type":"p","ImageSide":1,"ImageName":"arcPattern.webp","Text":"They did this by printing the first layer of an overhang in small circular sections. The sections are filled in a way that the plastic always has something to stick to. This method has some minor flaws, but it also highlights the potential of our printers. However the center of the circles tends to droop down due to excess heating. Another issue is warping. Arc overhangs tend to warp as new layers are printed on top of them. This warping happens because the layers are too thin to support themselves. When the next layer starts shrinking due to cooling, they can easily warp. This can be fixed by adding small supports in the corners of the layer to keep them in place during cooling. But this does add back some extra material. While it's a good approach and should be added to most slicers. For my goals, this isn't good enough."},{"Id":10,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"A completely different approach"},{"Id":11,"Type":"p","ImageSide":0,"ImageName":null,"Text":"If neither method gives us what we want we will just have to look even further from the norm. Which means ditching geometric shapes as the foundation for our layers. This is where, a method I've been experimenting with over the past year comes in, V-slicing. This method manages to incorporate the advantages of arc overhangs and conical slicing. It does this while countering their drawbacks. Granted it has its unique problems which I will have to address. The goal is to develop a slicer that is simple to use while reducing wasted material. This method can potentially print over 90° on a stock Ender 3. This is just theoretical at this point but overhangs up to 90° have already been tested. while also managing to reduce stair stepping if not eliminate it in most cases. This, however, as with everything, comes at a cost. The algorithms used are logically simple but computationally complex."},{"Id":12,"Type":"p","ImageSide":0,"ImageName":null,"Text":"In Devlog 1, I showcase my results so far. I also explain some of the underlying algorithms I've used so far. I will elaborate on these when we get to their devlogs, as each devlog will explore the algorithms for each layer. My primary goal by doing this is improving 3D printing which is why, as I write a V-Slicing-based slicer called Crystalite, I will also elaborate on all the potential issues I encountered. During these devlogs my ultimate goal is print quality on par with or surpassing Cura. I hope you will join me in that process through future devlogs."}],"Id":0,"Title":"Journey To Slicing's Bleeding Edge","ShortDescription":"Join me at the forefront of 3D printing innovation. In this introductory devlog, we'll explore groundbreaking slicing techniques that challenge the status quo. From conical slicing to arc overhangs, we'll examine these alternative approaches their limitations, and advantages that form the foundation for V-Slicing."},{"Paragraphs":[{"Id":0,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"A New Approach"},{"Id":1,"Type":"p","ImageSide":0,"ImageName":null,"Text":"One tried-and-true method for tackling complex problems is discretizing them. When summoning forth the exact layer shape from the enigmatic and arcane realm of mathematics isn't possible, we have to simplify the problem. For example, figuring out where to place cones in conical slicing or finding areas with support similar to arc overhangs is tough. But if we turn the mesh into voxels, we can easily calculate each layer based on the previous ones. This way we can create layers with varying thickness and slope. These offer many advantages over planar layers. This is the fundamental idea behind V-slicing."},{"Id":3,"Type":"p","ImageSide":0,"ImageName":null,"Text":"Voxels are the cells of a 3D grid. This means that they can technically be any shape. In our case voxels won't be perfect cubes, this lets us change the resolution in each axis separately. Allowing for more detail if needed in specific directions."},{"Id":4,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"From Mesh to Gcode"},{"Id":5,"Type":"p","ImageSide":0,"ImageName":"","Text":"To convert a mesh to Gcode we have to refine it through several steps. <br> A basic V-slicer has 6 steps:<br>1. We load the model and apply any changes we want to the mesh. This includes scaling and rotating it as needed.<br>2. We generate our grid of voxels from the mesh. <br>3. We can create the layers using a breadth-first search where each shell will become a layer. <br>4. We cut out the infill pattern to reduce material usage. In some cases, infill could be left out completely. However, this can introduce some unprintable areas. As such it will be addressed after the first iterations are complete.<br>5. Toolpath generation, where we take our voxels and find the fastest way to print all of them. Here we have to use the least direction changes and unnecessary travel moves to increase print speeds.<br>6. We convert back from voxel coordinates to physical size. Then we convert the toolpath Gcode. While doing so we apply any material flow adjustments and export the result."},{"Id":6,"Type":"","ImageSide":3,"ImageName":"VSliceProcess.png","Text":""},{"Id":7,"Type":"p","ImageSide":0,"ImageName":null,"Text":"These are the steps of a simple V-Slicer however, simple won't cut it. In the simplest V-Slicer for example, the resolution is directly linked to nozzle size. This means that prints come out very blocky. Furthermore, slope angle either can't be limited or doing so causes layers to be split into many separate lines. Which leads to reduced print quality and structural strength. On top of that, the solution to both problems comes with noticeable increases to runtime. We will need to solve all of those issues if we want to match or surpass the quality of Cura."},{"Id":8,"Type":"h4","ImageSide":0,"ImageName":"","Text":"Early results"},{"Id":9,"Type":"p","ImageSide":0,"ImageName":null,"Text":"While developing V-Slicing, I created two test versions to find potential issues. These versions had basic UIs to aid debugging. One was written for Unity, which was a short-lived proof of concept. The other version was closer to an alpha build written in C# for WPF. I would like to go over the results of the latter. The lessons learned in that version will form the foundations of Crystalite development."},{"Id":10,"Type":"p","ImageSide":1,"ImageName":"Benchy.png","Text":"This is the test file used to evaluate quality and reliability. It is a modified Benchy that was given a stand so it is suspended in mid-air to test supportless capabilities. Do also note that the text from the bottom was removed for early slicer limitations. However, the latest test version could handle them properly. All test prints were printed on a mostly stock Ender3, with the only mods being a 0.6mm nozzle and bed leveling probe.  This was the first successful full-scale benchy I managed to print after 6 months of development. This version's biggest problem was that the resolution was directly linked to nozzle size and layer thickness was also linked to voxel size. This meant a relatively small maximum layer height to reduce the maximum slope. I sliced this model with a 0.8mm nozzle setting to increase print speed. This resulted in a layer height of 0.175mm but lesser quality on overhangs since arc overhang style overhangs line width must match nozzle diameter."},{"Id":11,"Type":"p","ImageSide":2,"ImageName":"BenchyVoxelization.png","Text":"Because the resolution here was 0.8mm, the voxelization artifacts are easily visible on curved areas. A unique quirk of this version was that it had stair stepping like artifact on xy but not z like most slicers do due to relatively low resolution in xy compared to z. This will have to be eliminated in Crystalite by decoupling resolution from nozzle size. This wasn't done in early builds since it required a much more complex toolpath generation algorithm. On the other hand, increasing resolution will increase slicing time which will have to be reduced. The most obvious way to do so is to use the GPU via OpenCL. We can't use CUDA since that is NVIDIA-specific and we want it to be able to work on both Intel, AMD, and integrated graphics too. This leaves only OpenCL for our compute framework."},{"Id":12,"Type":"p","ImageSide":1,"ImageName":"OverhangSurface.png","Text":"When I first examined the print I was delighted with the quality of the horizontal overhang. This overhang method should only work when the line width matches the nozzle size. Considering this the result for a 0.8mm line width on a 0.6mm nozzle, it is quite clean. This shows that V-Slicing successfully integrates the strengths of conical slicers and arc overhangs while negating their weaknesses. We can also see how the layer's shape changes to best fit the model. This however can cause issues. The text for example had to be removed in this version because it would result in areas that tried to print below already printed areas. This was fixed when I changed the layer generation logic, and so it won't be a problem in Crystalite. This fix also allows layers to become thicker when that is possible without causing a collision. This also has the unexpected side effect of eliminating stair stepping almost completely on any printed layer thickness given a high enough z resolution."},{"Id":13,"Type":"p","ImageSide":0,"ImageName":null,"Text":"Since I made that test print, I have added multiple upgrades to the test build. However, I realized that the fundamentals needed to change so much that I chose to do a complete rewrite. This is due to many reasons. In the first two versions, infill was added during voxelization. This however also meant that some areas that had support printed as if they were overhangs resulting in worse print quality and reduced print speeds. For this reason, infill was moved to after layer generation which isn't possible in the test version cleanly. The way voxels are stored needs to change as well. The test version uses hash sets which isn't a bad option, but if we want to use the GPU we need to replace it with arrays. This means that a rewrite is necessary.<br>I tested greedy layers, which is a method meant to increase layer thickness by printing a benchy. During this test print there was an off-by-one error somewhere in the code leading to major over-extrusion and an unusable part. However greedy layers did provide the expected result of much faster print times with heavily reduced stair stepping where visible from the ~30-40% over extrusion. At this point, I already decided on a complete rewrite so I didn't bother finding the error. As such I am not planning on releasing this test build. Instead, I will focus on Crystalite development and releasing a polished, safe-to-use slicer."},{"Id":14,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"Going forward"},{"Id":15,"Type":"p","ImageSide":0,"ImageName":null,"Text":"I will try to get devlogs out as often as possible, but given that each focuses on a stage of the slicer, release intervals may vary. As such I decided to create a <a href=\"https://discord.gg/zXv3kGv7QG\" target=\"_blank\" rel=\"noopener noreferrer\">Discord</a> server where I will post a notification when a new devlog is out. It's also a place where you can share your thoughts about the project. And if you would like to support development I have also set up a <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://patreon.com/GeekWorks?utm_medium=unknown&utm_source=join_link&utm_campaign=creatorshare_creator&utm_content=copyLink\">Patreon</a> page where I will be posting a few behind-the-scenes photos and updates."},{"Id":16,"Type":"p","ImageSide":0,"ImageName":null,"Text":"In the next devlog, I will be starting work on the actual code for Crystalite. That devlog will be about code structure, mesh import, and voxelization. Development will have two phases, the first one will be getting the algorithms to work together and creating the UI for it. The second phase will focus on migrating the code from the CPU to the GPU to decrease slicing time."}],"Id":1,"Title":"Beyond geometrical shapes","ShortDescription":"In this devlog, I will be explaining the fundamentals of, and some of my experiences from developing, V-Slicing, a brand-new slicing method built on simple ideas. Designed to overcome the limitations of current methods. I also showcase a test print sliced with one of the development versions. We will look at the limitations of this basic implementation of the method."},{"Paragraphs":[{"Id":0,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"The first step towards non-planar printing"},{"Id":1,"Type":"p","ImageSide":0,"ImageName":null,"Text":"As the core of V-Slicing relies on voxels we need to find a method to convert our mesh into a useful format. I decided to start this process by importing the mesh using Assimp, which makes pretty much every 3D model format importable. To fix up the mesh a bit I use the option to merge nearby vertices, this makes sure that we don't get gaps between the triangles, which shouldn't happen often, but it did come up in testing due to rounding errors. However, this was the point where the simple no-brainer decisions ended."},{"Id":2,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"Rounding errors, and robustness"},{"Id":4,"Type":"p","ImageSide":0,"ImageName":null,"Text":"I've tried 3 methods for voxelizing the mesh, each having its pros and cons. The first was the most obvious to me, making a grid along xy, placing vertical lines in every grid square, and then running the Möller–Trumbore algorithm to get all ray-triangle intersections along the line."},{"Id":5,"Type":"p","ImageSide":1,"ImageName":"Moller.webp","Text":"Once we have these points we can utilize the fact that we know which side of the triangle we hit and start drawing if the triangle hit has a negative value in its normal for the z coordinate( the triangle faces down) and stop drawing voxels at the next point where the normal's z is positive(the triangle faces up). This is good for multiple reasons. First of all, we know when we are inside of the mesh and can fill the mesh completely. Second, we can theoretically handle walls inside the model... But as you can guess since this was the first method and I tried 2 others... this didn't really work."},{"Id":6,"Type":"p","ImageSide":0,"ImageName":null,"Text":"This method should probably work better, but I most likely messed something up on top of some basic logical issues. When I implemented this method I noticed that the whole inside/outside distinction didn't work well and I think I know why. The reason was the next major issue, missing triangles when checking from voxels. Who'd have thought, that if you try to check a whole grid cell with a single line you will end up missing triangles that don't hit the line but are inside the voxel... This led to points that didn't get closed at the right height, for example, the benchy doors were somewhat filled in. Or the stand I added and the areas around the flag holder had holes in the infill. I implemented a \"voting\" system or cellular automata if a cell had at least x neighbors of the opposing type out of the 3 types which are shell, infill, and air then it would swap to that type. This mostly worked but the whole process took too long, as you have to run it multiple times for it to work best. The intersection calculation could be optimized to be faster to some extent by a quadtree, so we only checked relevant triangles for a line, but the holes remained and sometimes ruined the slicing process. We need something more robust and reliable."},{"Id":7,"Type":"p","ImageSide":1,"ImageName":"DF.webp","Text":"I figured that if the issue was small gaps, I would just add an extra padding with a DF. A distance field is a function that tells you how far away from something you are, they are commonly used in computer graphics. So I implemented a triangle DF function and it worked mostly, but the amount of padding needed from the triangle to close the gaps was so large that the object looked puffy, which was an interesting effect(may add that later as an artistic effect), but it wasn't good for dimensionally accurate parts. The more interesting part of this process was the corrosion system I added to fill the mesh. Step one was adding the shell, this didn't help determine the inside of the mesh, but it did give us a mold to fill. We then fill the whole bounding box of the object with infill marked voxels, then we add all the infills that touch air(or have voxels that are outside the grid) to a queue. After this, we run a breadth-first search to corrode away all parts that touch air. We don't corrode voxels that have at least 3-4 shell voxels attached, which helps fill in random 1 voxel holes. This method doesn't care about extra walls inside the mesh but does mean a puffy mesh."},{"Id":8,"Type":"p","ImageSide":0,"ImageName":null,"Text":"Incomes rasterization, which is usually a way of turning triangles into pixels, which are the 2d equivalent of voxels. It's a fast process with relatively simple algorithms. The new method keeps the corrosion step but replaces the df-based shell generation removing the puffy effect. On top of being more accurate, it is also faster, as we only traverse active voxels of the triangle. With the DF algorithm, we checked every voxel of the triangle's bounding box, which meant that we would check a lot of voxels that weren't actually part of the triangle."},{"Id":9,"Type":"p","ImageSide":1,"ImageName":"Raster.webp","Text":"Voxelizing a triangle this way is fast and simple. We first convert the triangle's vertices into voxel coordinate space. Then we can draw a perfect voxel line along all 3 edges with Bresanham's line algorithm. We add the edge voxels to a list which we then group by z and order by xy. We then draw a line between all points of the groups. Usually most groups have just two voxels but grouping and drawing lines between all voxels that come after each other makes it more robust. This produces a mostly correct triangle, but since we grouped by z we will have gaps when looking from certain angles. To remedy this we run this two more times grouping by x and then by y in those runs. We then add all the voxels to the voxel mesh, and the separate passes cover the gaps for their respective axis, giving us a perfectly voxelized triangle."},{"Id":10,"Type":"p","ImageSide":0,"ImageName":null,"Text":"The corrosion and the new shell voxelization together give us a properly voxelized mesh. This method also retains dimensional accuracy. There is one problem, the code was written to work, not work fast. It collects each triangle's voxels into a collection(mostly has maps to speed up checking for specific voxels). Which then gets merged with the other triangles' voxels. From this, we remove duplicates and then add them to another hashset that represents the voxel mesh. These steps take quite a long time. On top of this the heavy use of LINQ results in large amounts of memory and processing power wasted. I used the .AsParallel() which allows for some level of automagical loop parallelism. However this usually only pushes my CPU to 50%. Furthermore, the corrosion step is a basic breadth-first search, which is single core. All these inefficiencies result in voxelization taking minutes at a resolution of 0.4mm for the floating benchy."},{"Id":11,"Type":"h4","ImageSide":0,"ImageName":null,"Text":"Time for some optimization"},{"Id":12,"Type":"p","ImageSide":0,"ImageName":null,"Text":"What I've described up to this point was the proof of concept slicer's voxelization stage. For the rewrite performance like that is just plain unacceptable. So I got to work. The first fundamental change was creating an abstraction for voxel meshes. I created an interface called IVoxelCollection. The purpose of this abstraction will be to allow for using different internal data structures to be less locked into something like I got in the first version with hashmaps."},{"Id":13,"Type":"p","ImageSide":0,"ImageName":null,"Text":"The interface has a Contains(pos) and WithinBounds(pos), where Contains calls WithinBounds and also checks if the given voxel is active, this makes the actual code easier to read. The key is that every class that inherits from IVoxelCollection must implement the [] set get functions(like you would use an array), this means that due to polymorphism I can use an IVoxelCollection variable in the logic where the actual collection gets passed in from outside. Like this, I can change the type of collection used to anything as long as I wrap it in a custom class that inherits IVoxelCollection and the logic won't break. This came in handy while developing, as I wanted to see which would be faster. A 1D array or a 3D array. I wanted to see the differences, turns out they are almost the same with 1D arrays just barely beating out 3D arrays winning by about 1s in voxelization(8sec vs 9sec) and the same in layer generation(15s instead of 16s) even with the ids having to be calculated the 1D arrays seems to come out on top while also using a 100mb less ram(2.7 GB vs 2.8 GB). As you can see the performance for voxelization will be improved significantly from 6-8 minutes to 8-9 seconds. This doesn't mean that we get a 60x performance improvement, as the old slice times were for 0.4mm resolution the new tests are run at the target resolution for this rewrite of 0.1mm which means that 64 times the voxels were processed leading to an improvement of more than 3500 times in voxelization."},{"Id":14,"Type":"p","ImageSide":0,"ImageName":null,"Text":"How did I achieve that level of performance? With multiple steps over two days of staring at a blank console until a time pops up when it's done, and also exporting the STL to check in cura, which surprisingly proved to be the most convenient STL viewer that I currently have installed, as blender takes too many steps to import a model."},{"Id":15,"Type":"p","ImageSide":0,"ImageName":null,"Text":"The first step was removing needless complexity by switching to the proper data structure for something like this. This was for most of the testing C#'s built-in 3D array. There are downsides like the immense memory usage. 2.7 GB for a benchy is too much, but for now, it is usable and that's what matters and I can swap it out later to something better thanks to the interface. I will most likely use something like an oct-tree with the nodes being arrays where each voxel is at most a single byte. I'm not sure how much of a performance impact replacing the hashset was since a HashSet-based IVoxelCollection wouldn't work properly with the highly parallel nature of the new code. So that means at least a 16x performance increase from multithreading by replacing that."},{"Id":16,"Type":"p","ImageSide":0,"ImageName":null,"Text":"After this, I removed the increased complexity that came from trying to use 16 threads with a hashmap. This included not collecting active voxels from every triangle into a single temporary collection. The rewrite passes in a reference to the voxel collection to each triangle which then can just set any voxel they want to be a shell value. Since we just care about which voxels are shells and which aren't, we don't need synchronization as we don't care which triangle sets the value to 1. This removes 2 unions of lists per triangle. By this time the voxelization was starting to get performant compared to the old version as a 0.1mm benchy took around 1-2 minutes to voxelize, which was about a 256x improvement when accounting for the 4x higher resolution. It was getting close to being usable. After this, I took the liberty to reorder some logic to remove unnecessary calculations. I didn't spend much time benchmarking here, so I don't remember the times."},{"Id":17,"Type":"p","ImageSide":0,"ImageName":null,"Text":"The last phase was improving the longest step, the corrosion which still takes 9x as much as shell creation and filling the mesh with infill values combined. The old system used breadth-first search and a queue, not very multi-thread friendly. I tried to use that but with some thread-safe collections which did help but it was taking too long and too many threads were idle. With the thread-safe collections, I got it to around 21-27 seconds based on which collection type I used and how many voxels each thread took when its own queue ran out. Adding this smaller queue made it so each thread had its own stash and so could work longer without having to stand in line for the next batch shortening the line as the threads would run out at different times. At this point, the only reason I kept going was that I knew how long iterating through each voxel took and I knew that it was not long at all. And since both operations are O(N) I knew that there had to be a better option. I realized something when I looked at it at this point. Each voxel's type was effectively a flag that meant that it could still be added since if it was corroded away it wasn't an infill type anymore. I used this to remove synchronizing threads completely. Now I just let threads corrode anything and the worst-case scenario is that some threads almost completely overlap, but this wouldn't usually last long just based on pure luck. This improved it a few seconds but not much. After this, I used a heuristic approach to improve it. I created a few seed points about as many as the number of physical threads. In reality about 3x of the number of hardware threads seems to be a sweet spot. I also switched to depth-first search, this may at first seem like it wouldn't change much, but it results in the threads mainly going down and then spreading out, which means less overlap between threads, and the number of seed points meant that if a thread stopped it had other places to pick up at, while not creating too much overhead by switching too many times."},{"Id":18,"Type":"p","ImageSide":0,"ImageName":null,"Text":"With all of these optimizations, I ended up with the blazing fast voxelization step of 8-9 seconds with everything included at a higher resolution which will be key to improving the shell's accuracy. Improving slice times this much shoved me that even slice times may be competitive with current slicers if a little more hardware-intense. I plan on keeping slice times below a minute for roughly benchy-sized objects. Which I'm on track for, I already have the code for layer generation. Layers are a bit trickier as seemingly it isn't a multi-threaded problem, since the next layer always requires the previous layer's shape with this approach, but with some clever tricks, I managed to utilize 100% of my CPU and generate an average benchy layer in about 50ms which results in a 15s layer generation for the 266 nonplanar layers that make up a floating benchy. Join me next time to learn how I went insane trying to shave minutes off the layer generation too. If you want to get notified about new devlogs or ask me about the slicer you can join the  <a href=\"https://discord.gg/zXv3kGv7QG\" target=\"_blank\" rel=\"noopener noreferrer\">GeekWorks discord server</a>."},{"Id":3,"Type":"p","ImageSide":0,"ImageName":null,"Text":"A major consideration for me was how each method handles mesh errors. For example, missing walls, walls inside the mesh that shouldn't be there. This is because I've found that a lot of freely available models have atrocious topology. I'm not throwing shade towards the people who model them, as that isn't an easy process and they are posting the files for free, I have no right to complain, especially since errors like these are really easy to make on a high-resolution model in blender. This however means that we have to account for it and make the voxelization step as robust as possible."}],"Id":2,"Title":"Block-by-Block","ShortDescription":"Join me on my journey towards supportless slicing in this devlog where we tackle rounding errors and optimize our methods for immense amounts of data. We will explore how specific algorithms can be used to voxelize a mesh."}],"Title":"Crystalite","HighlightImageName":"Images/Devlog0/Devlog0Thumbnail.png","ShortDescription":"Crystalite is a work-in-progress V-slicing based slicer that aims to compete with mainstream slicers in terms of usability and quality."}]}